{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fb6c026-c542-4867-801c-ef05d58e79e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "with open('C:\\\\Users\\\\micha\\\\Desktop\\\\LLM_api_keys\\\\OPENAI_API_KEY.txt') as f:\n",
    "    os.environ['OPENAI_API_KEY'] = f.readlines()[0].strip()\n",
    "    \n",
    "with open('C:\\\\Users\\\\micha\\\\Desktop\\\\LLM_api_keys\\\\GOOGLE_API_KEY.txt') as f:\n",
    "    os.environ['GOOGLE_API_KEY'] = f.readlines()[0].strip()\n",
    "    \n",
    "with open('C:\\\\Users\\\\micha\\\\Desktop\\\\LLM_api_keys\\\\GOOGLE_CSE_ID.txt') as f:\n",
    "    os.environ['GOOGLE_CSE_ID'] = f.readlines()[0].strip()\n",
    "    \n",
    "openai.organization = \"org-BEHI1MXnPmhI52h3LJBSY8e2\"\n",
    "openai.api_key = os.environ['OPENAI_API_KEY'] \n",
    "\n",
    "def get_response(content, role='user', model=\"gpt-3.5-turbo\"):\n",
    "    completion = openai.ChatCompletion.create(model=model,messages=[{\"role\": role,\"content\": content}])\n",
    "    return completion['choices'][0]['message']['content'], completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df3ecfe-4f91-4d6b-91b7-17e44c3651ff",
   "metadata": {},
   "source": [
    "<font size=\"5\">Models </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0672eb98-57d5-4a37-a349-46b28884ab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name=\"text-ada-001\", n=2, best_of=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2809e24a-c241-41e2-8ceb-9a74ba807088",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_result = llm([\"Hello, world!\", \"Goodbye, cruel world\"]*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68b5a78b-356f-4546-91d4-e342e8ee5a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, world!Goodbye, cruel worldHello, world!Goodbye, cruel worldHello, world!Goodbye, cruel worldHello, world!Goodbye, cruel worldHello, world!Goodbye, cruel worldHello, world!Goodbye, cruel worldHello, world!Goodbye, harsh worldHello, world!Goodbye, harsh worldHello, world!Goodbye, harsh worldHello, world!Goodbye, harsh worldHello, world!Goodbye, harsh worldHello, world!Goodbye, harsh worldHello, world!Goodbye, harsh worldHello, world!Goodbye, harsh worldHello, world!Goodbye, harsh worldHello, world!Goodbye, harsh worldHello, world!Goodbye, harsh worldHello, world!Goodbye, harsh worldHello, world!Goodbye, harsh worldHello, world!Goodbye, harsh worldHello, world!Goodbye, harsh worldHello, world!Goodbye, harsh worldHello, world!Goodbye, harsh worldHello, world!Goodbye, cruel worldHello, world!Goodbye, world!Goodbye, cruel worldHello, world!Goodbye, world!Goodbye, harsh worldHello, world!Goodbye, world!Goodbye,'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f100740-12f2-4d94-abe8-6fc52e99da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "chat = OpenAI(model_name=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2d071de-80f1-43e4-a8bb-18208efa8e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_result = chat.generate([\"Hello, world!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb2fb051-a405-499b-a2c2-4beee04be195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text='Hello! How can I help you today?', generation_info=None)]], llm_output={'token_usage': <OpenAIObject at 0x2c266432e50> JSON: {\n",
       "  \"completion_tokens\": 9,\n",
       "  \"prompt_tokens\": 11,\n",
       "  \"total_tokens\": 20\n",
       "}, 'model_name': 'gpt-4'})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49af3eec-8ffa-4592-bb5d-5ecfb4bc9194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(\"Why did the chicken cross the road?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c3ef419-02bf-458f-8b9f-dad99e8db8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should search for Olivia Wilde's boyfriend and then use a calculator to calculate his age raised to the 0.23 power.\n",
      "Action: Google Search\n",
      "Action Input: Olivia Wilde's boyfriend\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIn January 2021, Wilde began dating singer Harry Styles after meeting during the filming of Don't Worry Darling. Their relationship ended in November 2022. Mar 10, 2023 ... Olivia Wilde started dating Harry Styles after ending her years-long engagement to Jason Sudeikis — see their relationship timeline. Jan 29, 2023 ... Looks like Olivia Wilde and Jason Sudeikis are starting 2023 on good terms. Amid their highly publicized custody battle – and the actress' ... Jan 5, 2021 ... Wilde met Sudeikis in May 2011 at a Saturday Night Live wrap party following the season 36 finale. They began dating that November and got ... Before getting cozy with the “Watermelon Sugar” crooner, Wilde was in a long-term relationship with “SNL” alum Jason Sudeikis. But she and Sudeikis, 45, called ... Feb 23, 2023 ... Everything We Know About Olivia Wilde and Harry Styles's Relationship ... The former couple are \"still very close friends.\" ... When photographs of ... Feb 23, 2023 ... Olivia Wilde's anger at ex-boyfriend Harry Styles: She resents him and thinks he was using her ... The two started dating after Wilde split up ... Nov 18, 2022 ... Olivia Wilde's Boyfriend: Everything To Know About Reported Ex Harry Styles & Ex Jason Sudeikis · Olivia Wilde and Jason Sudeikis were in a ... 4.2m Followers, 596 Following, 1896 Posts - See Instagram photos and videos from Olivia Wilde (@oliviawilde) Jan 7, 2021 ... Olivia Wilde's ex-boyfriend is Jason Sudeikis. The pair began dating in 2011 and became engaged two years later.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the calculator to calculate Harry Styles' age raised to the 0.23 power.\n",
      "Action: Calculator\n",
      "Action Input: 24^0.23\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 2.0770578163554174\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Harry Styles, Olivia Wilde's boyfriend, is 24 years old and his age raised to the 0.23 power is 2.0770578163554174.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Total Tokens: 1731\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'OpenAICallbackHandler' object has no attribute 'prompt_tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m response \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWho is Olivia Wilde\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms boyfriend? What is his current age raised to the 0.23 power?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal Tokens: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcb\u001b[38;5;241m.\u001b[39mtotal_tokens\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt Tokens: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcb\u001b[38;5;241m.\u001b[39mprompt_tokens\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompletion Tokens: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcb\u001b[38;5;241m.\u001b[39mcompletion_tokens\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal Cost (USD): $\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcb\u001b[38;5;241m.\u001b[39mtotal_cost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'OpenAICallbackHandler' object has no attribute 'prompt_tokens'"
     ]
    }
   ],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "# from langchain.agents import AgentType\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "tools = load_tools([\"google-search\", \"llm-math\"], llm=llm)\n",
    "agent = initialize_agent(tools, llm, verbose=True)\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    response = agent.run(\"Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?\")\n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d707e493-7f3e-4515-b6d7-3546c44148c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "A $prompt \\ value$ refers to the input (text) data that is passed to the underlying (language) $model$. The model then \"infers\" a $completion$ for the given input. For now, Lang Chain only supports textimport llm_api_keys prompts, but there are plans to move on to more complex data types (combinations of text, video, audio, etc.).\n",
    "\n",
    "Below, we walk through a simple example where we pass a $prompt \\ value$ to a language $model$, and print the $completion$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ba3b5a48-4f0d-4256-b477-7fd21f73b90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A model is a system of lips that produce a sound when you speak. The model is composed of lips that produce a sound that is related to a sound file. The sound file is stored on a device that can be seen or represented by a model. The model can speak and write language.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "model = OpenAI(model_name=\"text-ada-001\")\n",
    "\n",
    "prompt_value = \"Hello, language model!\"\n",
    "\n",
    "completion = model(prompt_value)\n",
    "\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff48dca5-aa7d-48f5-a3f8-315fbe13950c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000122"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_num_tokens(completion)/1000*0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c274ee42-836f-4e63-aedc-9e7e166768cd",
   "metadata": {},
   "source": [
    "$Prompt \\ templates$ take in input variables, and output prompt values. A key skill for a prompt engineer is to develop prompt templates that users can easily and intuitivly interact with, and that get the desired behavior from the underlying model.\n",
    "\n",
    "Let's look at an example;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054fd131-0760-4d16-9845-365c736e8a7d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb4b3439-6b61-4dd0-a7bb-9c06a7b19763",
   "metadata": {},
   "source": [
    "<font size=\"5\">No Prompt Template </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053e5180-26ec-4b29-bb7a-56c32d58b00d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a47af93-f283-443b-8809-72a94ebfa46d",
   "metadata": {},
   "source": [
    "<font size=\"5\">Prompt Template </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d469d425-40c0-4a2a-970b-e91bd9eadd3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb26f55e-18f0-4ce4-8482-38dd2e73a062",
   "metadata": {},
   "source": [
    "<font size=\"5\">Better Prompt Template </font>\n",
    "\n",
    "Prompts can be improved by using $Example \\ Selectors$ of desired outputs to specific prompts. Model responses can be guided toward structure using $Output \\ Parsers$;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364be38c-c1b9-4e69-bb68-50491bcded74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f497992f-a1d8-4b4a-9d9c-281707ee149c",
   "metadata": {},
   "source": [
    "<font size=\"5\">Working with documents </font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
