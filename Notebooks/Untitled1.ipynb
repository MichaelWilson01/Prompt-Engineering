{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fb6c026-c542-4867-801c-ef05d58e79e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "with open('C:\\\\Users\\\\micha\\\\Desktop\\\\LLM_api_keys\\\\OPENAI_API_KEY.txt') as f:\n",
    "    os.environ['OPENAI_API_KEY'] = f.readlines()[0].strip()\n",
    "    \n",
    "with open('C:\\\\Users\\\\micha\\\\Desktop\\\\LLM_api_keys\\\\GOOGLE_API_KEY.txt') as f:\n",
    "    os.environ['GOOGLE_API_KEY'] = f.readlines()[0].strip()\n",
    "    \n",
    "with open('C:\\\\Users\\\\micha\\\\Desktop\\\\LLM_api_keys\\\\GOOGLE_CSE_ID.txt') as f:\n",
    "    os.environ['GOOGLE_CSE_ID'] = f.readlines()[0].strip()\n",
    "    \n",
    "openai.organization = \"org-BEHI1MXnPmhI52h3LJBSY8e2\"\n",
    "openai.api_key = os.environ['OPENAI_API_KEY'] \n",
    "\n",
    "def get_response(content, role='user', model=\"gpt-3.5-turbo\"):\n",
    "    completion = openai.ChatCompletion.create(model=model,messages=[{\"role\": role,\"content\": content}])\n",
    "    return completion['choices'][0]['message']['content'], completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df3ecfe-4f91-4d6b-91b7-17e44c3651ff",
   "metadata": {},
   "source": [
    "<font size=\"5\">Models </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0672eb98-57d5-4a37-a349-46b28884ab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name=\"text-ada-001\", n=2, best_of=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2809e24a-c241-41e2-8ceb-9a74ba807088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nHello, world!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12784646-2bc1-49c9-a1f2-fc86f6f29f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyllamacpp --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f100740-12f2-4d94-abe8-6fc52e99da02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a145ac09-fbe4-4f66-9891-ae622e75221f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GPT4All' from 'langchain.llms' (C:\\Users\\micha\\anaconda3\\lib\\site-packages\\langchain\\llms\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT4All\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m GPT4All(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/gpt4all-model.bin\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, n_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Simplest invocation\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'GPT4All' from 'langchain.llms' (C:\\Users\\micha\\anaconda3\\lib\\site-packages\\langchain\\llms\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain.llms import GPT4All\n",
    "model = GPT4All(model=\"./models/gpt4all-model.bin\", n_ctx=512, n_threads=8)\n",
    "\n",
    "# Simplest invocation\n",
    "response = model(\"Once upon a time, \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda22b78-77b0-4abe-8975-436ba48f6d25",
   "metadata": {},
   "source": [
    "A $prompt \\ value$ refers to what is passed to the underlying model. For now, Lang Chain only supports $text$ prompts, but will likely move on to more complex data types (combinations of text, video, audio, etc.).\n",
    "\n",
    "$Prompt \\ templates$ take in input variables, and output prompt values. A key skill for a prompt engineer is to develop prompt templates that users can easily and intuitivly interact with, and that get the desired behavior from the underlying model.\n",
    "\n",
    "Let's look at an example;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da066e8-a7af-4e68-90f7-d4aa47c060a9",
   "metadata": {},
   "source": [
    "<font size=\"5\">No Prompt Template </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053e5180-26ec-4b29-bb7a-56c32d58b00d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5db3119-3a79-4d0a-ba50-b7f407dab35c",
   "metadata": {},
   "source": [
    "<font size=\"5\">Prompt Template </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d469d425-40c0-4a2a-970b-e91bd9eadd3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bfe201b-d56f-410a-a2f3-b26a600355ff",
   "metadata": {},
   "source": [
    "<font size=\"5\">Better Prompt Template </font>\n",
    "\n",
    "Prompts can be improved by using $Example \\ Selectors$ of desired outputs to specific prompts. Model responses can be guided toward structure using $Output \\ Parsers$;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364be38c-c1b9-4e69-bb68-50491bcded74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "602e8c63-7697-410b-a8ec-71451bd6ba09",
   "metadata": {},
   "source": [
    "<font size=\"5\">Working with documents </font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
