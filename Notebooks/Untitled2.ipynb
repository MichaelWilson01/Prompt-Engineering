{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b48142a1-5a61-4e6b-bcba-41049efb09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import llm_api_keys\n",
    "\n",
    "openai.organization = os.environ['OPENAI_ORGANIZATION']\n",
    "openai.api_key = os.environ['OPENAI_API_KEY'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405dbcaf-0993-42fe-8ea6-1206c8333f44",
   "metadata": {
    "tags": []
   },
   "source": [
    "A $prompt \\ value$ refers to the input (text) data that is passed to the underlying (language) $model$. The model then \"infers\" a $completion$ for the given input. For now, Lang Chain only supports textimport llm_api_keys prompts, but there are plans to move on to more complex data types (combinations of text, video, audio, etc.).\n",
    "\n",
    "Below, we walk through a simple example where we pass a $prompt \\ value$ to a language $model$, and print the $completion$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "258b87f2-b96d-4444-a880-c4ce013f8624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A model is a language that can be solved by writing code in it. This code can be used to represent a set of words or data in a language. The model can be used to solve problems in that language.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "model = OpenAI(model_name=\"text-ada-001\")\n",
    "\n",
    "prompt_value = \"Hello, language model!\"\n",
    "\n",
    "completion = model(prompt_value)\n",
    "\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ad6b8b-d312-4f46-8b3e-9a31e2a9985b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.2e-05"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_num_tokens(completion)/1000*0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497f886d-e3ac-47c8-8eeb-0544bfc123e0",
   "metadata": {},
   "source": [
    "$Prompt \\ templates$ take in input variables, and output prompt values. A key skill for a prompt engineer is to develop prompt templates that users can easily and intuitivly interact with, and that get the desired behavior from the underlying model.\n",
    "\n",
    "Let's look at an example;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534cc4e5-a4a5-4b02-b353-ccd0d881e9ee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f7bc31a-bc45-4034-ba1c-6c1d08864348",
   "metadata": {},
   "source": [
    "<font size=\"5\">No Prompt Template </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19faa8f3-a338-41ac-8f62-266edae2f8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "735ecb5a-23fa-47c3-a4aa-dad5aa502fb5",
   "metadata": {},
   "source": [
    "<font size=\"5\">Prompt Template </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc12fad4-7d3c-4494-8e40-9d24fca78868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b0673b8-02d4-48a5-aa33-34acfbc67f1b",
   "metadata": {},
   "source": [
    "<font size=\"5\">Better Prompt Template </font>\n",
    "\n",
    "Prompts can be improved by using $Example \\ Selectors$ of desired outputs to specific prompts. Model responses can be guided toward structure using $Output \\ Parsers$;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d22b9a8-c890-491d-b4d6-2356bf2a4101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3478bda4-5608-4de8-914b-8ca5a49dc512",
   "metadata": {},
   "source": [
    "<font size=\"5\">Working with documents </font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
